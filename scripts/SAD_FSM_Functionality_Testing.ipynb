{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy.signal import filtfilt, butter, iirnotch, welch\n",
    "import math\n",
    "from collections import deque\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-01T15:59:48.241-05\n"
     ]
    }
   ],
   "source": [
    "data, words, starts, ends = extract_data.extract_data(r\"C:\\Users\\lwing\\Downloads\\College\\Spring 2022\\Senior Design II\\SilentSpeechDAS\\fEMGData\\mouthed_full_6_set1.txt\", r\"C:\\Users\\lwing\\Downloads\\College\\Spring 2022\\Senior Design II\\silent-speech\\scripts\\Mouthed_Full_6_set1.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_1 = data[:,0]\n",
    "chan_2 = data[:,1]\n",
    "chan_3 = data[:,2]\n",
    "chan_4 = data[:,3]\n",
    "chan_5 = data[:,4]\n",
    "chan_6 = data[:,5]\n",
    "channel_data = [chan_1, chan_2, chan_3, chan_4, chan_5, chan_6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating target variable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chan_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(791100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(starts)):\n",
    "    y[starts[i]:ends[i]+1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186972\n",
      "791100\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(y))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Band Pass to demonstrate most prominent frequency range]\n",
    "low_cutoff = 20\n",
    "high_cutoff = 450\n",
    "\n",
    "filtered_data = [0,0,0,0,0,0]\n",
    "\n",
    "for idx, channel in enumerate(channel_data):\n",
    "    signal_meancorrect = channel - np.mean(channel)\n",
    "    \n",
    "    #60Hz Notch Filter for Power Line Noise\n",
    "    b, a = iirnotch(60, 30, 1000)\n",
    "    signal_notched = filtfilt(b, a, signal_meancorrect)\n",
    "\n",
    "    # Fourth Order Butterworth \n",
    "    b, a = butter(10, [low_cutoff, high_cutoff], fs=1000, btype='bandpass')\n",
    "    signal_filtered = filtfilt(b, a, signal_notched)\n",
    "\n",
    "    #Rectify signal\n",
    "    filtered_data[idx] = abs(signal_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Extraneous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting indices :24887,486094-504933, 763442:\n",
    "\n",
    "for i in range(len(filtered_data)):\n",
    "    arr1 = filtered_data[i][24887:486094]\n",
    "    arr2 = filtered_data[i][504933:763442]\n",
    "    filtered_data[i] = np.concatenate([arr1, arr2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = y[24887:486094]\n",
    "arr2 = y[504933:763442]\n",
    "y = np.concatenate([arr1, arr2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#large window to average over\n",
    "window = 40\n",
    "        \n",
    "        #overlap interval\n",
    "skip = 20\n",
    "        \n",
    "ind1 = 0\n",
    "ind2 = window\n",
    "y_new = np.zeros(int(len(y)/20)+1)\n",
    "i = 0\n",
    "while ind1 < len(y):\n",
    "            \n",
    "    #remaining data less than window size, avoid array out of bounds\n",
    "    if ind2 > len(y):\n",
    "        ind2 = len(y)-1\n",
    "                \n",
    "    num_label = np.count_nonzero(y[ind1:ind2])\n",
    "    if num_label > 19:\n",
    "        y_new[i] = 1\n",
    "    ind1 = ind1 + skip\n",
    "    ind2 = ind2 + skip\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35986"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping filtered data with rms, smoothing, and downsampling operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(raw):\n",
    "        rms_window = deque([0,0,0,0,0])\n",
    "        rms_data = np.zeros(len(raw))\n",
    "        for i, sample in enumerate(raw):\n",
    "            rms_window.popleft()\n",
    "            rms_window.append(sample)\n",
    "            val = np.sqrt(sum(np.square(rms_window)/5))\n",
    "            rms_data[i] = val\n",
    "            \n",
    "        return rms_data\n",
    "    \n",
    "    \n",
    "#TO DO: MAKE SURE ARRAY OUT OF BOUNDS CHECK IS SUFFICIENT\n",
    "def smooth(rms_data):\n",
    "        \n",
    "    #large window to average over; sampling rate is 1000 Hz; each sample is a millisecond\n",
    "    window = 40\n",
    "        \n",
    "    #overlap interval\n",
    "    skip = 20\n",
    "        \n",
    "    ind1 = 0\n",
    "    ind2 = window\n",
    "    #assuming that the packet size i.e. length of raw data and rms_data will be a multiple of 20\n",
    "    downsampled = np.zeros(int(len(rms_data)/20)+1)\n",
    "    i = 0\n",
    "    while ind1 < len(rms_data):\n",
    "            \n",
    "        #remaining data less than window size, avoid array out of bounds\n",
    "        if ind2 > len(rms_data):\n",
    "            ind2 = len(rms_data)-1\n",
    "                \n",
    "        val = np.mean(rms_data[ind1:ind2], dtype=np.float64)\n",
    "        downsampled[i] = val\n",
    "        ind1 = ind1 + skip\n",
    "        ind2 = ind2 + skip\n",
    "        i = i+1\n",
    "            \n",
    "    return downsampled\n",
    "        \n",
    "def calculate(smoothed_envelope):\n",
    "        \n",
    "    return np.abs(np.diff(smoothed_envelope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data = [0,0,0,0,0,0]\n",
    "\n",
    "for i in range(len(filtered_data)):\n",
    "    data_rms = rms(filtered_data[i])\n",
    "    res = smooth(data_rms)\n",
    "    ready_data[i] = calculate(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35985\n",
      "35985\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(ready_data[0]))\n",
    "print(len(ready_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = y_new[:35985]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSM Testing Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_results = [0,0,0,0,0,0]\n",
    "for i in range(6):\n",
    "    channel_results[i] = np.zeros(35985)\n",
    "\n",
    "for idx, channel in enumerate(ready_data):\n",
    "    active = False\n",
    "    max_power = 0\n",
    "    min_power = 1\n",
    "    max_thresh = .5\n",
    "    min_thresh = 2\n",
    "    for index, sample in enumerate(channel):\n",
    "        \n",
    "        if active:\n",
    "            if sample > (max_power * max_thresh):\n",
    "                active = True\n",
    "                channel_results[idx][index] = 1\n",
    "            else:\n",
    "                active = False\n",
    "                channel_results[idx][index] = 0\n",
    "            if sample > max_power:\n",
    "                max_power = sample\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if sample < (min_power * min_thresh):\n",
    "                active = False\n",
    "                channel_results[idx][index] = 0\n",
    "            else:\n",
    "                active = True\n",
    "                channel_results[idx][index] = 1\n",
    "            if sample < min_power:\n",
    "                min_power = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel 0: Accuracy = 0.50054, Confusion Matrix = [[13434 13424]\n",
      " [ 4549  4578]]\n",
      "Channel 1: Accuracy = 0.50143, Confusion Matrix = [[13432 13426]\n",
      " [ 4515  4612]]\n",
      "Channel 2: Accuracy = 0.50043, Confusion Matrix = [[13426 13432]\n",
      " [ 4545  4582]]\n",
      "Channel 3: Accuracy = 0.50099, Confusion Matrix = [[13437 13421]\n",
      " [ 4536  4591]]\n",
      "Channel 4: Accuracy = 0.50015, Confusion Matrix = [[13429 13429]\n",
      " [ 4558  4569]]\n",
      "Channel 5: Accuracy = 0.50118, Confusion Matrix = [[13441 13417]\n",
      " [ 4533  4594]]\n"
     ]
    }
   ],
   "source": [
    "for chan, predicted in enumerate(channel_results):\n",
    "    accuracy = accuracy_score(predicted,y_new)\n",
    "    cm=confusion_matrix(y_new, predicted) \n",
    "    print(f\"Channel {chan}: Accuracy = {accuracy:.5f}, Confusion Matrix = {cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
